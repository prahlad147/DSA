********** What is an Algorithm ************
-> An algorithm is a set of well-defined instructions in sequence to solve a problem.




********** Qualities of Good Algorithms **********
-> 1. Input and output should be defined precisely.
   2. Each step in the algorithm should be clear and unambiguous.
   3. Algorithms should be most effective among many different ways to solve a problem.
   4. An algorithm shouldn't include computer code. Instead, the algorithm should be written in such a way that it can be used in different 
      programming languages.
      
      
      

*********** Time and Space Complexity ***********
-> Time Complexity -> Lesser time involved.
-> Space Complexity -> Fewer memory involved.


-> Two of the most valuable resources for a computer program are time and memory.
-> The time taken by the computer to run code is: 
   Time to run code = number of instructions * time to execute each instruction
-> The number of instructions depends on the code you used, and the time taken to execute each code depends on your machine and compiler.




********** Code ***********
-> If it was written in a programming language, we would call it to code instead.



********** Scalability **********
-> Scalability is scale plus ability, which means the quality of an algorithm/system to handle the problem of larger size.




************ Asymptotic Analysis? **********

-> The efficiency of an algorithm depends on the amount of time, storage and other resources required to execute the algorithm. 
-> The efficiency is measured with the help of asymptotic notations.
-> The study of change in performance of the algorithm with the change in the order of the input size is defined as asymptotic analysis.




*********** Asymptotic Notations? ***********

-> Asymptotic notations are the mathematical notations used to describe the running time of an algorithm when the input tends towards a particular value or a 
limiting value.



There are mainly three asymptotic notations:
• Big-O notation
• Omega notation
• Theta notation




********** Big-O Notation (O-notation)? ***********

-> Big-O notation represents the upper bound of the running time of an algorithm. 
-> Thus, it gives the worst-case complexity of an algorithm.

-> O gives the upper bound of a function

      O(g(n)) = { f(n): there exist positive constants c and n0 such that 0 ≤ f(n) ≤ cg(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set O(g(n)) if there exists a positive constant c such that it lies between 0 and cg(n), 
   for sufficiently large n.

-> For any value of n, the running time of an algorithm does not cross the time provided by O(g(n)).

-> Since it gives the worst-case running time of an algorithm, it is widely used to analyze an algorithm as we are always interested in the worst-case scenario.




*********** Omega Notation (Ω-notation)? ************

-> Omega notation represents the lower bound of the running time of an algorithm. 
-> Thus, it provides the best case complexity of an algorithm.

-> Ω gives the lower bound of a function

      Ω(g(n)) = { f(n): there exist positive constants c and n0 such that 0 ≤ cg(n) ≤ f(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set Ω(g(n)) if there exists a positive constant c such that it lies above cg(n), for 
   sufficiently large n.

-> For any value of n, the minimum time required by the algorithm is given by Omega Ω(g(n)).




********** Theta Notation (Θ-notation)? ************

-> Theta notation encloses the function from above and below. 
-> Since it represents the upper and the lower bound of the running time of an algorithm, it is used for 
   analyzing the average-case complexity of an algorithm.

-> Theta bounds the function within constants factors.

-> For a function g(n), Θ(g(n)) is given by the relation:
      
      Θ(g(n)) = { f(n): there exist positive constants c1, c2 and n0 such that 0 ≤ c1g(n) ≤ f(n) ≤ c2g(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set Θ(g(n)) if there exist positive constants c1 and c2 such that it can be sandwiched 
   between c1g(n) and c2g(n), for sufficiently large n.

-> If a function f(n) lies anywhere in between c1g(n) and c2g(n) for all n ≥ n0, then 
   f(n) is said to be asymptotically tight bound.




********** Master Theorem? **********

-> The master method is a formula for solving recurrence relations of the form:
   
   T(n) = aT(n/b) + f(n),
where,
n = size of input
a = number of subproblems in the recursion
n/b = size of each subproblem. All subproblems are assumed to have the same size.
f(n) = cost of the work done outside the recursive call, which includes the cost of dividing the problem and cost of merging the solutions.
 
 
-> Here, a ≥ 1 and b > 1 are constants, and f(n) is an asymptotically positive function.

-> An asymptotically positive function means that for a sufficiently large value of n,  we have f(n) > 0.




-> The master theorem is used in calculating the time complexity of recurrence relations (divide and conquer algorithms) in a simple and quick way.

-> If a ≥ 1 and b > 1 are constants and f(n) is an asymptotically positive function, then the time complexity of a recursive relation is given by
   
   T(n) = aT(n/b) + f(n)

where, T(n) has the following asymptotic bounds:
 1. If f(n) = O(nlogb a-ϵ), then T(n) = Θ(nlogb a).
 2. If f(n) = Θ(nlogb a), then T(n) = Θ(nlogb a * log n).
 3. If f(n) = Ω(nlogb a+ϵ), then T(n) = Θ(f(n)).
ϵ > 0 is a constant.


-> Each of the above conditions can be interpreted as:
1. If the cost of solving the sub-problems at each level increases by a certain factor, the value of f(n) will become polynomially smaller than nlogb a. 
Thus, the time complexity is oppressed by the cost of the last level ie. nlogb a

2. If the cost of solving the sub-problem at each level is nearly equal, then the value of f(n) will be nlogb a. Thus, the time complexity will be f(n) times the 
total number of levels ie. nlogb a * log n.

3. If the cost of solving the subproblems at each level decreases by a certain factor, the value of f(n) will become polynomially larger than nlogb a. Thus, 
the time complexity is oppressed by the cost of f(n).




-> Solved Example of Master Theorem

T(n) = 3T(n/2) + n2
Here,
a = 3
n/b = n/2
f(n) = n2
logb a = log2 3 ≈ 1.58 < 2
ie. f(n) < nlogb
a+ϵ , where, ϵ is a constant.
Case 3 implies here.
Thus, T(n) = f(n) = Θ(n2) 
Master Theorem Limitations




-> The master theorem cannot be used if:

   • T(n) is not monotone. eg. T(n) = sin n
   • f(n) is not a polynomial. eg. f(n) = 2n
   • a is not a constant. eg. a = 2n
   • a < 1




********** Divide and Conquer Algorithm **********

-> A divide and conquer algorithm is a strategy of solving a large problem by

   1. breaking the problem into smaller sub-problems
   2. solving the sub-problems, and
   3. combining them to get the desired output.

-> To use the divide and conquer algorithm, recursion is used.




********** How Divide and Conquer Algorithms Work? **********

-> Here are the steps involved:
1. Divide: Divide the given problem into sub-problems using recursion.
2. Conquer: Solve the smaller sub-problems recursively. If the subproblem is small enough, then solve it directly.
3. Combine: Combine the solutions of the sub-problems that are part of the recursive process to solve the actual problem.


********** Divide and Conquer Vs Dynamic approach ***********

-> The divide and conquer approach divides a problem into smaller subproblems; these subproblems are further solved recursively. The result of each subproblem 
   is not stored for future reference, whereas, in a dynamic approach, the result of each subproblem is stored for future reference.
   
-> Use the divide and conquer approach when the same subproblem is not solved multiple times. 
-> Use the dynamic approach when the result of a subproblem is to be used multiple times in the future.






********** Advantages of Divide and Conquer Algorithm **********

   • The complexity for the multiplication of two matrices using the naive method is O(n^3), whereas using the divide and conquer approach (i.e. 
      Strassen's matrix multiplication) is O(n^2.8074). This approach also simplifies other problems, such as the Tower of Hanoi.
   • This approach is suitable for multiprocessing systems.
   • It makes efficient use of memory caches.


*********** Divide and Conquer Applications ***********

   • Binary Search
   • Merge Sort
   • Quick Sort
   • Strassen's Matrix multiplication
   • Karatsuba Algorithm




*********** Stack Data Structure ************

-> A stack is a useful data structure in programming. A stack is an object (an abstract data type).
-> It is just like a pile of plates kept on top of each other.
-> Stack representation similar to a pile of plate.


-> Think about the things you can do with such a pile of plates
• Put a new plate on top
• Remove the top plate


-> If you want the plate at the bottom, you must first remove all the plates on top. 
-> Such an arrangement is called Last In First Out - the last item that is the first item to go out.




************ LIFO Principle of Stack **********

-> In programming terms, putting an item on top of the stack is called push and removing an item is called pop.




*********** Basic Operations of Stack ***********

-> A stack is an object (an abstract data type - ADT) that allows the following operations:

   • Push: Add an element to the top of a stack
   • Pop: Remove an element from the top of a stack
   • IsEmpty: Check if the stack is empty
   • IsFull: Check if the stack is full
   • Peek: Get the value of the top element without removing it




********** Stack Time Complexity ***********

-> For the array-based implementation of a stack, the push and pop operations take constant time, i.e. O(1)




********** Applications of Stack Data Structure **********

-> Although stack is a simple data structure to implement, it is very powerful. 

-> The most common uses of a stack are:

   • To reverse a word - Put all the letters in a stack and pop them out. Because of the LIFO order of stack, you will get the letters in reverse order.
   • In compilers - Compilers use the stack to calculate the value of expressions like 2 + 4 / 5 * (7 - 9) by converting the expression to prefix or postfix form.
   • In browsers - The back button in a browser saves all the URLs you have visited previously in a stack. Each time you visit a new page, it is added on 
      top of the stack. When you press the back button, the current URL is removed from the stack, and the previous URL is accessed.




*********** Queue Data Structure **********

-> A queue is a useful data structure in programming. A queue is an object (an abstract data type - ADT).

-> It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.


-> Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.




********** FIFO Principle of Queue ***********

-> In programming terms, putting items in the queue is called enqueue, and removing items from the queue is called dequeue.




********** Basic Operations of Queue **********

-> A queue is an object (an abstract data structure - ADT) that allows the following operations:

   • Enqueue: Add an element to the end of the queue
   • Dequeue: Remove an element from the front of the queue
   • IsEmpty: Check if the queue is empty
   • IsFull: Check if the queue is full
   • Peek: Get the value of the front of the queue without removing it




*********** Complexity Analysis of Queue Operations ***********

-> The complexity of enqueue and dequeue operations in a queue using an array is O(1).




*********** Applications of Queue ************

   • CPU scheduling, Disk Scheduling
   • When data is transferred asynchronously between two processes. The queue is used for synchronization. For example: IO Buffers, pipes, file IO, etc.
   • Handling of interrupts in real-time systems.
   • Call Center phone systems use Queues to hold people calling them in order.




********** Types of Queues ************

There are four different types of queues:
• Simple Queue
• Circular Queue
• Priority Queue
• Double Ended Queue




*********** Simple Queue ***********

-> In a simple queue, insertion takes place at the rear and removal occurs at the front. 
-> It strictly follows the FIFO (First in First out) rule.




************ Circular Queue ***********

-> In a circular queue, the last element points to the first element making a circular link.




************ Simple Queue Vs Circular Queue ***********

-> The main advantage of a circular queue over a simple queue is better memory utilization. 
-> If the last position is full and the first position is empty, we can insert an element in the first position. 
-> This action is not possible in a simple queue.




*********** Priority Queue ************

-> A priority queue is a special type of queue in which each element is associated with a priority and is served according to its priority. 
-> If elements with the same priority occur, they are served according to their order in the queue.
-> Insertion occurs based on the arrival of the values and removal occurs based on priority.




************ Deque (Double Ended Queue) ************

-> In a double ended queue, insertion and removal of elements can be performed from either from the front or rear. 
-> Thus, it does not follow the FIFO (First In First Out) rule.




************ Circular Queue Data Structure ************

-> Circular queue avoids the wastage of space in a regular queue implementation using arrays.




************ How Circular Queue Works ************

-> Circular Queue works by the process of circular increment i.e. when we try to increment the pointer and we reach the end of the queue, we start from the 
   beginning of the queue.

-> Here, the circular increment is performed by modulo division with the queue size. 

-> That is,
      if REAR + 1 == 5 (overflow!), REAR = (REAR + 1)%5 = 0 (start of queue).
      
      
      
      
************ Circular Queue Complexity Analysis ************

-> The complexity of the enqueue and dequeue operations of a circular queue is O(1) for (array implementations).




************* Applications of Circular Queue ************

   • CPU scheduling
   • Memory management
   • Traffic Management


************ Priority Queue ***********

-> A priority queue is a special type of queue in which each element is associated with a priority and is served according to its priority. 
-> If elements with the same priority occur, they are served according to their order in the queue.

-> Generally, the value of the element itself is considered for assigning the priority.
-> For example, The element with the highest value is considered as the highest 
   priority element. 




************ Difference between Priority Queue and Normal Queue ***********

-> In a queue, the first-in-first-out rule is implemented whereas, in a priority queue, the values are removed on the basis of priority. 
-> The element with the highest priority is removed first.




*********** Implementation of Priority Queue ***********

-> Priority queue can be implemented using an array, a linked list, a heap data structure, or a binary search tree. 
-> Among these data structures, heap data structure provides an efficient implementation of priority queues.

-> A comparative analysis of different implementations of priority queue is given below.

   Operations          peek  insert    delete
   Linked List         O(1)  O(n)      O(1)
   Binary Heap         O(1)  O(log n)  O(log n)
   Binary Search Tree  O(1)  O(log n)  O(log n)




************ Priority Queue Operations ***********

-> Basic operations of a priority queue are inserting, removing, and peeking elements


1. Inserting an Element into the Priority Queue

Inserting an element into a priority queue (max-heap) is done by the following steps.
   
   • Insert the new element at the end of the tree.  
   • Insert an element at the end of the queue 
   • Heapify the tree. 
   • Heapify after insertion




2. Deleting an Element from the Priority Queue

Deleting an element from a priority queue (max-heap) is done as follows:

   • Select the element to be deleted. 
   • Swap it with the last element. 
   • Swap with the last leaf node element 
   • Remove the last element. 
   • Remove the last element leaf 
   • Heapify the tree. 
   • Heapify the priority queue 




3. Peeking from the Priority Queue (Find max/min)

Peek operation returns the maximum element from Max Heap or minimum element from Min Heap without deleting the node.




4. Extract-Max/Min from the Priority Queue

Extract-Max returns the node with maximum value after removing it from a Max Heap whereas Extract-Min returns the node with minimum value after removing it 
from Min Heap.




*********** Priority Queue Applications ************

Some of the applications of a priority queue are:
   • Dijkstra's algorithm
   • for implementing stack
   • for load balancing and interrupt handling in an operating system
   • for data compression in Huffman code




*********** Deque Data Structure ***********

-> Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can be performed from either from the front or rear. 
-> Thus, it does not follow FIFO rule (First In First Out).




*********** Types of Deque ***********

   • Input Restricted Deque
   In this deque, input is restricted at a single end but allows deletion at both the ends.
   • Output Restricted Deque
   In this deque, output is restricted at a single end but allows insertion at both the ends.




*********** Operations on a Deque ************

-> Below is the circular array implementation of deque. In a circular array, if the array is full, we start from the beginning.
-> But in a linear array implementation, if the array is full, no more elements can be inserted. 
-> In each of the operations below, if the array is full, "overflow message" is thrown.




*********** Time Complexity ************

-> The time complexity of all the above operations is constant i.e. O(1).




*********** Applications of Deque Data Structure ************

1. In undo operations on software.
2. To store history in browsers.
3. For implementing both stacks and queues




********** Linked list Data Structure **********

-> A linked list data structure includes a series of connected nodes. 
-> Here, each node store the data and the address of the next node.


-> You have to start somewhere, so we give the address of the first node a special name called HEAD.
-> Also, the last node in the linked list can be identified because its next portion points to NULL.


-> You might have played the game Treasure Hunt, where each clue includes the information about the next clue. That is how the linked list operates.


********** Representation of Linked List **********

Each node consists:
• A data item
• An address of another node.




-> The power of a linked list comes from the ability to break the chain and rejoin it. 

E.g. if you wanted to put an element 4 between 1 and 2, the steps would be:
• Create a new struct node and allocate memory to it.
• Add its data value as 4
• Point its next pointer to the struct node containing 2 as the data value
• Change the next pointer of "1" to the node we just created.




*********** Linked List Complexity ***********

Time Complexity

Operations  Worst case  Average Case
Search      O(n)        O(n)
Insert      O(1)        O(1)
Deletion    O(1)        O(1)


Space Complexity: O(n)




********** Linked List Applications **********

• Dynamic memory allocation
• Implemented in stack and queue
• In undo functionality of softwares
• Hash tables, Graphs




*********** Linked List Operations: Traverse, Insert and Delete **********

Two important points to remember:
• head points to the first node of the linked list
• next pointer of the last node is NULL, so if the next current node is NULL, we have reached the end of the linked list.




********** Traverse a Linked List **********

-> Displaying the contents of a linked list is very simple.
-> We keep moving the temp node to the next one and display its contents.
-> When temp is NULL, we know that we have reached the end of the linked list so we get out of the while loop.




********** Insert Elements to a Linked List **********

-> You can add elements to either the beginning, middle or end of the linked list.


1. Insert at the beginning
• Allocate memory for new node
• Store data
• Change next of new node to point to head
• Change head to point to recently created node


2. Insert at the End
• Allocate memory for new node
• Store data
• Traverse to last node
• Change next of last node to recently created node


3. Insert at the Middle
• Allocate memory and store data for new node
• Traverse to node just before the required position of new node
• Change next pointers to include new node in between




********** Delete from a Linked List **********

-> You can delete either from the beginning, end or from a particular position.


1. Delete from beginning
• Point head to the second node


2. Delete from end
• Traverse to second last element
• Change its next pointer to null


3. Delete from middle
• Traverse to element before the element to be deleted
• Change next pointers to exclude the node from the chain




********** Types of Linked List **********

There are three common types of Linked List.
• Singly Linked List
• Doubly Linked List
• Circular Linked List




********** Singly Linked List **********

-> It is the most common. Each node has data and a pointer to the next node.




********** Doubly Linked List **********

-> We add a pointer to the previous node in a doubly-linked list. Thus, we can go in either direction: forward or backward.




********** Circular Linked List **********

-> A circular linked list is a variation of a linked list in which the last element is linked to the first element. 
-> This forms a circular loop.


-> A circular linked list can be either singly linked or doubly linked.
• for singly linked list, next pointer of last item points to the first item.
• In the doubly linked list, prev pointer of the first item points to the last item as well.




************ Hash Table **********

-> The Hash table data structure stores elements in key-value pairs where
• Key- unique integer that is used for indexing the values
• Value - data that are associated with keys.




*********** Hashing **********

-> Hashing is a technique of mapping a large set of arbitrary data to tabular indexes using a hash function. 
-> It is a method for representing dictionaries for large datasets.
-> It allows lookups, updating and retrieval operation to occur in a constant time i.e. O(1).




*********** Why Hashing is Needed **********

-> After storing a large amount of data, we need to perform various operations on these data. 
-> Lookups are inevitable for the datasets. 
-> Linear search and binary search perform lookups/search with time complexity of O(n) and O(log n) respectively. 
-> As the size of the dataset increases, these complexities also become significantly high which is not acceptable.

-> We need a technique that does not depend on the size of data. 
-> Hashing allows lookups to occur in constant time i.e. O(1)




*********** Hash Function **********

-> A hash function is used for mapping each element of a dataset to indexes in the table.

-> In a hash table, a new index is processed using the keys. 
-> And, the element corresponding to that key is stored in the index. This process is called hashing.

-> Let k be a key and h(x) be a hash function.
-> Here, h(k) will give us a new index to store the element linked with k.




*********** Hash Collision ***********

-> When the hash function generates the same index for multiple keys, there will be a conflict (what value to be stored in that index). 
-> This is called a hash collision.


-> We can resolve the hash collision using one of the following techniques.
• Collision resolution by chaining
• Open Addressing: Linear/Quadratic Probing and Double Hashing




1. Collision resolution by chaining
-> In chaining, if a hash function produces the same index for multiple elements, these elements are stored in the same index by using a doubly-linked list.
-> If j is the slot for multiple elements, it contains a pointer to the head of the list of elements. If no element is present, j contains NIL.

2. Open Addressing
-> Unlike chaining, open addressing doesn't store multiple elements into the same slot. 
-> Here, each slot is either filled with a single key or left NIL.


Different techniques used in open addressing are:

i. Linear Probing
-> In linear probing, collision is resolved by checking the next slot.
   
   h(k, i) = (h′(k) + i) mod m
   where,
   • i = {0, 1, ….}
   • h'(k) is a new hash function

-> If a collision occurs at h(k, 0), then h(k, 1) is checked. 
-> In this way, the value of i is incremented linearly.


-> The problem with linear probing is that a cluster of adjacent slots is filled. 
-> When inserting a new element, the entire cluster must be traversed. 
-> This adds to the time required to perform operations on the hash table.




ii. Quadratic Probing
-> It works similar to linear probing but the spacing between the slots is increased (greater than one) by using the following relation.

   h(k, i) = (h′(k) + c1i + c2i^2) mod m
   where,
   • c1 and c2 are positive auxiliary constants,
   • i = {0, 1, ….}




iii. Double hashing
-> If a collision occurs after applying a hash function h(k), then another hash function is calculated for finding the next slot.

   h(k, i) = (h1(k) + ih2(k)) mod m




*********** Good Hash Functions **********

-> A good hash function may not prevent the collisions completely however it can reduce the number of collisions.



-> Here, we will look into different methods to find a good hash function

1. Division Method
-> If k is a key and m is the size of the hash table, the hash function h() is calculated as:

   h(k) = k mod m

-> For example, If the size of a hash table is 10 and k = 112 then h(k) = 112 mod 10 = 2. 
-> The value of m must not be the powers of 2. This is because the powers of 2 in binary format are 10, 100, 1000, …. 
-> When we find k mod m, we will always get the lower order p-bits.
   if m = 22, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 01
   if m = 23, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 001
   if m = 24, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 0001
   if m = 2p, then h(k) = p lower bits of m




2. Multiplication Method

   h(k) = ⌊m(kA mod 1)⌋
   where,
   • kA mod 1 gives the fractional part kA,
   • ⌊ ⌋ gives the floor value
   • A is any constant. The value of A lies between 0 and 1. But, an optimal choice will be ≈ (√5-1)/2 suggested by Knuth.




3. Universal Hashing

-> In Universal hashing, the hash function is chosen at random independent of keys




********** Applications of Hash Table **********

-> Hash tables are implemented where
• constant time lookup and insertion is required
• cryptographic applications
• indexing data is required




********** Heap Data Structure **********

-> Heap data structure is a complete binary tree that satisfies the heap property. It is also called as a binary heap.

-> A complete binary tree is a special binary tree in which
• every level, except possibly the last, is filled
• all the nodes are as far left as possible




*********** Heap Property **********

-> Heap Property is the property of a node in which:

• (for max heap) key of each node is always greater than its child node/s and the key of the root node is the largest among all other nodes;

• (for min heap) key of each node is always smaller than the child node/s and the key of the root node is the smallest among all other nodes.




********** Heap Operations **********

-> Some of the important operations performed on a heap are described below along with their algorithms: Heapify




********** Heapify **********

->Heapify is the process of creating a heap data structure from a binary tree. It is used to create a Min-Heap or a Max-Heap.

   1. Let the input array.
   2. Create a complete binary tree from the array
   3. Start from the first index of non-leaf node whose index is given by n/2 - 1.
   4. Set current element i as largest.
   5. The index of left child is given by 2i + 1 and the right child is given by 2i + 2.
      If leftChild is greater than currentElement (i.e. element at ith index), set leftChildIndex as largest.
      If rightChild is greater than element in largest, set rightChildIndex as largest.
   6. Swap largest with currentElement
   7. Repeat steps 3-7 until the subtrees are also heapified.





*********** Insert Element into Max Heap **********

1. Insert the new element at the end of the tree.
2. Heapify the tree.

-> For Min Heap, the above algorithm is modified so that parentNode is always smaller than newNode.


********** Delete Element from Max Heap **********

1. Select the element to be deleted.
2. Swap it with the last element.
3. Remove the last element.
4. Heapify the tree.

-> For Min Heap, above algorithm is modified so that both childNodes are greater smaller than currentNode.




*********** Peek (Find max/min) **********

-> Peek operation returns the maximum element from Max Heap or minimum element from Min Heap without deleting the node.

-> For both Max heap and Min Heap

   return rootNode




********** Extract-Max/Min **********

-> Extract-Max returns the node with maximum value after removing it from a Max Heap.
-> whereas Extract-Min returns the node with minimum after removing it from Min Heap.




*********** Heap Data Structure Applications **********

• Heap is used while implementing a priority queue.
• Dijkstra’s Algorithm
• Heap Sort




********** Tree Data Structure **********

A tree is a nonlinear hierarchical data structure that consists of nodes connected by edges.




********** Linear Vs Non-Linear Data Structure ***********

-> In linear data structure, all data elements are present at a single level. 
-> Linear data structures are easier to implement.

-> In non-linear data structure, data elements are hierarchically connected and are present at various levels. 
-> In non-linear data structure, data elements are present at multiple levels.




********** Why Tree Data Structure? **********

-> Other data structures such as arrays, linked list, stack, and queue are linear data structures that store data sequentially. 
-> In order to perform any operation in a linear data structure, the time complexity increases with the increase in the data size. 
-> But, it is not acceptable in today's computational world.

-> Different tree data structures allow quicker and easier access to the data as it is a non-linear data structure.




********** Tree Terminologies **********

Node:

-> A node is an entity that contains a key or value and pointers to its child nodes.
-> The last nodes of each path are called leaf nodes or external nodes that do not contain a link/pointer to child nodes.
-> The node having at least a child node is called an internal node.



Edge:

-> It is the link between any two nodes.



Root:

-> It is the topmost node of a tree.


Height of a Node:

-> The height of a node is the number of edges from the node to the deepest leaf (ie. the longest path from the node to a leaf node).


Depth of a Node:

-> The depth of a node is the number of edges from the root to the node


Height of a Tree:

-> The height of a Tree is the height of the root node or the depth of the deepest node.


Degree of a Node:

-> The degree of a node is the total number of branches of that node.


Forest:

-> A collection of disjoint trees is called a forest.


Creating forest from a tree:

-> You can create a forest by cutting the root of a tree




********** Types of Tree **********

There are mainly four types of Tree:
1. Binary Tree
2. Binary Search Tree
3. AVL Tree
4. B-Tree




********** Tree Applications **********

   • Binary Search Trees(BSTs) are used to quickly check whether an element is present in a set or not.
   • Heap is a kind of tree that is used for heap sort.
   • A modified version of a tree called Tries is used in modern routers to store routing information.
   • Most popular databases use B-Trees and T-Trees, which are variants of the tree structure we learned above to store their data
   • Compilers use a syntax tree to validate the syntax of every program you write.




********** Tree Traversal - inorder, preorder and postorder **********

-> Traversing a tree means visiting every node in the tree. 
-> You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.


-> Linear data structures like arrays, stacks, queues, and linked list have only one way to read the data. 
-> But a hierarchical data structure like a tree can be traversed in different ways.


-> According to this structure, every tree is a combination of
• A node carrying data
• Two subtrees

-> Remember that our goal is to visit each node, so we need to visit all the nodes in the subtree, 
-> visit the root node and visit all the nodes in the right subtree as well.


-> Depending on the order in which we do this, there can be three types of traversal.


Inorder traversal:

1. First, visit all the nodes in the left subtree
2. Then the root node
3. Visit all the nodes in the right subtree


Preorder traversal:

1. Visit root node
2. Visit all the nodes in the left subtree
3. Visit all the nodes in the right subtree


Postorder traversal:

1. Visit all the nodes in the left subtree
2. Visit all the nodes in the right subtree
3. Visit the root node




********** Binary Tree **********

-> A binary tree is a tree data structure in which each parent node can have at most two children.




********** Types of Binary Tree ***********

Full Binary Tree:

-> A full Binary tree is a special type of binary tree in which every parent node/internal node has either two or no children.


Perfect Binary Tree:

-> A perfect binary tree is a type of binary tree in which every internal node has exactly two child nodes and all the leaf nodes are at the same level.



Complete Binary Tree:

-> A complete binary tree is just like a full binary tree, but with two major differences

   1. Every level must be completely filled
   2. All the leaf elements must lean towards the left.
   3. The last leaf element might not have a right sibling i.e. a complete binary tree doesn't have to be a full binary tree.



Degenerate or Pathological Tree:

-> A degenerate or pathological tree is the tree having a single child either left or right.


Skewed Binary Tree:

-> A skewed binary tree is a pathological/degenerate tree in which the tree is either dominated by the left nodes or the right nodes. 


Thus, there are two types of skewed binary tree: 
1.left-skewed binary tree.
2.right-skewed binary tree.



Balanced Binary Tree:

-> It is a type of binary tree in which the difference between the height of the left and the right subtree for each node is either 0 or 1.


********** Binary Tree Applications ***********

   • For easy and quick access to data
   • In router algorithms
   • To implement heap data structure
   • Syntax tree




********** Full Binary Tree **********

-> A full Binary tree is a special type of binary tree in which every parent node/internal node has either two or no children.
-> It is also known as a proper binary tree.




********** Full Binary Tree Theorems **********

   Let, i = the number of internal nodes
        n = be the total number of nodes
        l = number of leaves
        λ = number of levels


1. The number of leaves is i + 1.
2. The total number of nodes is 2i + 1.
3. The number of internal nodes is (n – 1) / 2.
4. The number of leaves is (n + 1) / 2.
5. The total number of nodes is 2l – 1.
6. The number of internal nodes is l – 1.
7. The number of leaves is at most 2^λ - 1.




********** Perfect Binary Tree **********

-> A perfect binary tree is a type of binary tree in which every internal node has exactly two child nodes and all the leaf nodes are at the same level.

-> All the internal nodes have a degree of 2.




-> Recursively, a perfect binary tree can be defined as:

1. If a single node has no children, it is a perfect binary tree of height h = 0,
2. If a node has h > 0, it is a perfect binary tree if both of its subtrees are of height h - 1 and are non-overlapping.




*********** Perfect Binary Tree Theorems **********

1. A perfect binary tree of height h has 2h + 1 – 1 node.
2. A perfect binary tree with n nodes has height log(n + 1) – 1 = Θ(ln(n)).
3. A perfect binary tree of height h has 2h leaf nodes.
4. The average depth of a node in a perfect binary tree is Θ(ln(n))




Complete Binary Tree:

-> A complete binary tree is a binary tree in which all the levels are completely filled except possibly the lowest one, which is filled from the left.

-> A complete binary tree is just like a full binary tree, but with two major differences
1. All the leaf elements must lean towards the left.
2. The last leaf element might not have a right sibling 
      i.e. a complete binary tree doesn't have to be a full binary tree.




Full Vs Complete Binary Trees:

-> A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children. 
-> A complete binary tree is a binary tree in which every level, except possibly the last, is completely filled, and all nodes are as far left as possible.




How a Complete Binary Tree is Created?

1. Select the first element of the list to be the root node. (no. of elements on level-I: 1)
2. Put the second element as a left child of the root node and the third element as the right child. (no. of elements on level-II: 2)
3. Put the next two elements as children of the left node of the second level. 
      Again, put the next two elements as children of the right node of the second level (no. of elements on level-III: 4) elements).
4. Keep repeating until you reach the last element.\




Relationship between array indexes and tree element:

-> A complete binary tree has an interesting property that we can use to find the children and parents of any node.
-> If the index of any element in the array is i, the element in the index 2i+1 will become the left child and element in 2i+2 index will become the right child. 
-> Also, the parent of any element at index i is given by the lower bound of (i-1)/2.




Complete Binary Tree Applications:
• Heap-based data structures
• Heap sort




Balanced Binary Tree:

-> A balanced binary tree, also referred to as a height-balanced binary tree, is defined as a binary tree in which
    the height of the left and right subtree of any node differ by not more than 1.


Following are the conditions for a height-balanced binary tree:
1. Difference between the left and the right subtree for any node is not more than one.
2. The left subtree is balanced.
3. The right subtree is balanced.



Balanced Binary Tree Applications:
• AVL tree
• Balanced Binary Search Tree



Binary Search Tree(BST):

-> Binary search tree is a data structure that quickly allows us to maintain a sorted list of numbers.
-> It is called a binary tree because each tree node has a maximum of two children.
-> It is called a search tree because it can be used to search for the presence of a number in O(log(n)) time.




The properties that separate a binary search tree from a regular binary tree is:
1. All nodes of left subtree are less than the root node.
2. All nodes of right subtree are more than the root node.
3. Both subtrees of each node are also BSTs i.e. they have the above two properties.




There are two basic operations that you can perform on a binary search tree:

1. Search Operation:

-> The algorithm depends on the property of BST that if each left subtree has values below root and each right subtree has values above the root.
-> If the value is below the root, we can say for sure that the value is not in the right subtree; we need to only search in the left subtree 
      and if the value is above the root, we can say for sure that the value is not in the left subtree; we need to only search in the right subtree.


Algorithm:
If root == NULL 
 return NULL;
If number == root -> data
 return root -> data;
If number < root -> data
 return search(root -> left)
If number > root -> data
 return search(root -> right)



2. Insert Operation:

-> Inserting a value in the correct position is similar to searching because we try to maintain 
      the rule that the left subtree is lesser than root and the right subtree is larger than root.
-> We keep going to either right subtree or left subtree depending on the value and when 
      we reach a point left or right subtree is null, we put the new node there.


Algorithm:
If node == NULL 
 return createNode(data)
if (data < node -> data)
 node -> left = insert(node -> left, data);
else if (data > node -> data)
 node -> right = insert(node -> right, data); 
return node;




Deletion Operation:

There are three cases for deleting a node from a binary search tree.

Case I:
-> In the first case, the node to be deleted is the leaf node. 
-> In such a case, simply delete the node from the tree.


Case II:
-> In the second case, the node to be deleted lies has a single child node. 
-> In such a case follow the steps below:
1. Replace that node with its child node.
2. Remove the child node from its original position.


Case III:
-> In the third case, the node to be deleted has two children. 
-> In such a case follow the steps below:
1. Get the inorder successor of that node.
2. Replace the node with the inorder successor.
3. Remove the inorder successor from its original position.




Binary Search Tree Complexities:

Time Complexity:

Operation     Best Case  Average Case  Worst Case
Search        O(log n)   O(log n)      O(n)
Insertion     O(log n)   O(log n)      O(n)
Deletion      O(log n)   O(log n)      O(n)

Here, n is the number of nodes in the tree.


Space Complexity:

-> The space complexity for all the operations is O(n).



Binary Search Tree Applications:
1. In multilevel indexing in the database
2. For dynamic sorting
3. For managing virtual memory areas in Unix kernel



Graph Data Stucture:

-> A graph data structure is a collection of nodes that have data and are connected to other nodes.

-> Let's try to understand this through an example. On facebook, everything is a node. 
-> That includes User, Photo, Album, Event, Group, Page, Comment, Story, Video, Link, Note...anything that has data is a node.


-> Every relationship is an edge from one node to another. 
-> Whether you post a photo, join a group, like a page, etc., a new edge is created for that relationship.


-> All of facebook is then a collection of these nodes and edges. 
-> This is because facebook uses a graph data structure to store its data.



More precisely, a graph is a data structure (V, E) that consists of:
• A collection of vertices V
• A collection of edges E, represented as ordered pairs of vertices (u,v)




In the graph,
V = {0, 1, 2, 3}
E = {(0,1), (0,2), (0,3), (1,2)}
G = {V, E}




Graph Terminology:

• Adjacency: 
-> A vertex is said to be adjacent to another vertex if there is an edge connecting them. 
-> Vertices 2 and 3 are not adjacent because there is no edge between them.

• Path: 
-> A sequence of edges that allows you to go from vertex A to vertex B is called a path. 
-> 0-1, 1-2 and 0-2 are paths from vertex 0 to vertex 2.

• Directed Graph: 
-> A graph in which an edge (u,v) doesn't necessarily mean that there is an edge (v, u) as well. 
-> The edges in such a graph are represented by arrows to show the direction of the edge.




Graph Representation:

Graphs are commonly represented in two ways:

1. Adjacency Matrix

-> An adjacency matrix is a 2D array of V x V vertices. 
-> Each row and column represent a vertex.
-> If the value of any element a[i][j] is 1, it represents that there is an edge connecting vertex i and vertex j.

-> Edge lookup (checking if an edge exists between vertex A and vertex B) is extremely fast in adjacency matrix representation but we have to reserve space for 
      every possible link between all vertices (V x V), so it requires more space.




Pros of adjacency matrix:

-> The basic operations like adding an edge, removing an edge and checking whether there is an edge from vertex i to vertex j 
      are extremely time efficient, constant time operations.
      
-> If the graph is dense and the number of edges is large, adjacency matrix should be the first choice. 
-> Even if the graph and the adjacency matrix is sparse, we can represent it using data structures for sparse matrices.

-> The biggest advantage however, comes from the use of matrices. 
-> The recent advances in hardware enable us to perform even expensive matrix operations on the GPU.

-> By performing operations on the adjacent matrix, we can get important insights into the nature of the graph and the relationship between its vertices.




Cons of adjacency matrix:

-> The VxV space requirement of the adjacency matrix makes it a memory hog. 

-> Graphs out in the wild usually don't have too many connections and this is the major reason why 
      adjacency lists are the better choice for most tasks.

-> While basic operations are easy, operations like inEdges and outEdges are expensive when using the adjacency matrix representation.



Adjacency Matrix Applications:
1. Creating routing table in networks
2. Navigation tasks




2. Adjacency List

-> An adjacency list represents a graph as an array of linked lists.
-> The index of the array represents a vertex and each element in its linked list represents the other vertices that form an edge with the vertex


-> An adjacency list is efficient in terms of storage because we only need to store the values for the edges. 
-> For a sparse graph with millions of vertices, this can mean a lot of saved space.


Adjacency List Structure:
-> The simplest adjacency list needs a node data structure to store a vertex and a graph data structure to organize the nodes.

-> We stay close to the basic definition of a graph - a collection of vertices and edges {V, E}. 
-> For simplicity, we use an unlabeled graph as opposed to a labeled one i.e. the vertices are identified by their indices 0,1,2,3.




Graph Operations:

The most common graph operations are:
• Check if the element is present in the graph.
• Graph Traversal.
• Add elements(vertex, edges) to graph.
• Finding the path from one vertex to another.




Note:
-> An undirected graph is a graph in which the edges do not point in any direction (ie. the edges are bidirectional).
-> A connected graph is a graph in which there is always a path from a vertex to any other vertex.
-> Dense graph is a graph in which the number of edges is close to the maximal number of edges. 
-> Sparse graph is a graph in which the number of edges is close to the minimal number of edges.



Spanning Tree and Minimum Spanning Tree:
-> A spanning tree is a sub-graph of an undirected connected graph, which includes all the vertices of the graph with a minimum possible number of edges. 
-> If a vertex is missed, then it is not a spanning tree.
-> The edges may or may not have weights assigned to them.


-> The total number of spanning trees with n vertices that can be created from a complete graph is equal to n^(n-2).


If we have n = 4, the maximum number of possible spanning trees is equal to 4^(4-2) = 16. 
Thus, 16 spanning trees can be formed from a complete graph with 4 vertices.




Minimum Spanning Tree:

-> A minimum spanning tree is a spanning tree in which the sum of the weight of the edges is as minimum as possible.


Notes:

The minimum spanning tree from a graph is found using the following algorithms:
1. Krusal's Algorithm
2. Prim's Algorithm



-> Kruskal's algorithm finds a minimum spanning forest of an undirected edge-weighted graph. 
-> If the graph is connected, it finds a minimum spanning tree. 
-> It is a greedy algorithm in graph theory as in each step it adds the next lowest-weight edge that will not form a cycle to the minimum spanning forest.


2. Prim's Algorithm:
-> Prim's algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. 
-> This means it finds a subset of the edges that forms a tree that includes every vertex, where the total weight of all the edges in the tree is minimized.




Spanning Tree Applications:
1. Computer Network Routing Protocol
2. Cluster Analysis
3. Civil Network Planning




Minimum Spanning tree Applications:
• To find paths in the map
• To design networks like telecommunication networks, water supply networks, and electrical grids.




Strongly Connected Components:

-> A strongly connected component is the portion of a directed graph in which there is a path from each vertex to another vertex. 
-> It is applicable only on a directed graph.
-> These components can be found using Kosaraju's Algorithm.


Strongly Connected Components Applications:
• Vehicle routing applications
• Maps
• Model-checking in formal verification


Kosaraju's Algorithm:

-> Kosaraju's Algorithm is based on the depth-first search algorithm implemented twice.

Three steps are involved:

1. Perform a depth first search on the whole graph.
-> Let us start from vertex-0, visit all of its child vertices, and mark the visited vertices as done. 
-> If a vertex leads to an already visited vertex, then push this vertex to the stack.

For example: Starting from vertex-0, go to vertex-1, vertex-2, and then to vertex-3. Vertex-3 leads to already visited vertex-0, 
      so push the source vertex (ie. vertex-3) into the stack.
      
      
2. Go to the previous vertex (vertex-2) and visit its child vertices i.e. vertex-4, vertex-5, vertex-6 and vertex-7 sequentially. 
      Since there is nowhere to go from vertex-7, push it into the stack.
   Go to the previous vertex (vertex-6) and visit its child vertices. 
      But, all of its child vertices are visited, so push it into the stack.
   Similarly, a final stack is created.


3. Reverse the original graph.

4. Perform depth-first search on the reversed graph.
-> Start from the top vertex of the stack. Traverse through all of its child vertices. 
-> Once the already visited vertex is reached, one strongly connected component is formed.

For example: Pop vertex-0 from the stack. Starting from vertex-0, traverse 
through its child vertices (vertex-0, vertex-1, vertex-2, vertex-3 in sequence) and mark them as visited. 
The child of vertex-3 is already visited, so these visited vertices form one strongly connected component.

Go to the stack and pop the top vertex if already visited. Otherwise, choose the top vertex from the stack and traverse through its child vertices as presented.
above.


5. Thus, we get the strongly connected components.




Kosaraju's Algorithm Complexity:
-> Kosaraju's algorithm runs in linear time i.e. O(V+E).


































































































