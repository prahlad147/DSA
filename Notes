********** What is an Algorithm ************
-> An algorithm is a set of well-defined instructions in sequence to solve a problem.




********** Qualities of Good Algorithms **********
-> 1. Input and output should be defined precisely.
   2. Each step in the algorithm should be clear and unambiguous.
   3. Algorithms should be most effective among many different ways to solve a problem.
   4. An algorithm shouldn't include computer code. Instead, the algorithm should be written in such a way that it can be used in different 
      programming languages.
      
      
      

*********** Time and Space Complexity ***********
-> Time Complexity -> Lesser time involved.
-> Space Complexity -> Fewer memory involved.


-> Two of the most valuable resources for a computer program are time and memory.
-> The time taken by the computer to run code is: 
   Time to run code = number of instructions * time to execute each instruction
-> The number of instructions depends on the code you used, and the time taken to execute each code depends on your machine and compiler.




********** Code ***********
-> If it was written in a programming language, we would call it to code instead.



********** Scalability **********
-> Scalability is scale plus ability, which means the quality of an algorithm/system to handle the problem of larger size.




************ Asymptotic Analysis? **********

-> The efficiency of an algorithm depends on the amount of time, storage and other resources required to execute the algorithm. 
-> The efficiency is measured with the help of asymptotic notations.
-> The study of change in performance of the algorithm with the change in the order of the input size is defined as asymptotic analysis.




*********** Asymptotic Notations? ***********

-> Asymptotic notations are the mathematical notations used to describe the running time of an algorithm when the input tends towards a particular value or a 
limiting value.



There are mainly three asymptotic notations:
• Big-O notation
• Omega notation
• Theta notation




********** Big-O Notation (O-notation)? ***********

-> Big-O notation represents the upper bound of the running time of an algorithm. 
-> Thus, it gives the worst-case complexity of an algorithm.

-> O gives the upper bound of a function

      O(g(n)) = { f(n): there exist positive constants c and n0 such that 0 ≤ f(n) ≤ cg(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set O(g(n)) if there exists a positive constant c such that it lies between 0 and cg(n), 
   for sufficiently large n.

-> For any value of n, the running time of an algorithm does not cross the time provided by O(g(n)).

-> Since it gives the worst-case running time of an algorithm, it is widely used to analyze an algorithm as we are always interested in the worst-case scenario.




*********** Omega Notation (Ω-notation)? ************

-> Omega notation represents the lower bound of the running time of an algorithm. 
-> Thus, it provides the best case complexity of an algorithm.

-> Ω gives the lower bound of a function

      Ω(g(n)) = { f(n): there exist positive constants c and n0 such that 0 ≤ cg(n) ≤ f(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set Ω(g(n)) if there exists a positive constant c such that it lies above cg(n), for 
   sufficiently large n.

-> For any value of n, the minimum time required by the algorithm is given by Omega Ω(g(n)).




********** Theta Notation (Θ-notation)? ************

-> Theta notation encloses the function from above and below. 
-> Since it represents the upper and the lower bound of the running time of an algorithm, it is used for 
   analyzing the average-case complexity of an algorithm.

-> Theta bounds the function within constants factors.

-> For a function g(n), Θ(g(n)) is given by the relation:
      
      Θ(g(n)) = { f(n): there exist positive constants c1, c2 and n0 such that 0 ≤ c1g(n) ≤ f(n) ≤ c2g(n) for all n ≥ n0 }

-> The above expression can be described as a function f(n) belongs to the set Θ(g(n)) if there exist positive constants c1 and c2 such that it can be sandwiched 
   between c1g(n) and c2g(n), for sufficiently large n.

-> If a function f(n) lies anywhere in between c1g(n) and c2g(n) for all n ≥ n0, then 
   f(n) is said to be asymptotically tight bound.




********** Master Theorem? **********

-> The master method is a formula for solving recurrence relations of the form:
   
   T(n) = aT(n/b) + f(n),
where,
n = size of input
a = number of subproblems in the recursion
n/b = size of each subproblem. All subproblems are assumed to have the same size.
f(n) = cost of the work done outside the recursive call, which includes the cost of dividing the problem and cost of merging the solutions.
 
 
-> Here, a ≥ 1 and b > 1 are constants, and f(n) is an asymptotically positive function.

-> An asymptotically positive function means that for a sufficiently large value of n,  we have f(n) > 0.




-> The master theorem is used in calculating the time complexity of recurrence relations (divide and conquer algorithms) in a simple and quick way.

-> If a ≥ 1 and b > 1 are constants and f(n) is an asymptotically positive function, then the time complexity of a recursive relation is given by
   
   T(n) = aT(n/b) + f(n)

where, T(n) has the following asymptotic bounds:
 1. If f(n) = O(nlogb a-ϵ), then T(n) = Θ(nlogb a).
 2. If f(n) = Θ(nlogb a), then T(n) = Θ(nlogb a * log n).
 3. If f(n) = Ω(nlogb a+ϵ), then T(n) = Θ(f(n)).
ϵ > 0 is a constant.


-> Each of the above conditions can be interpreted as:
1. If the cost of solving the sub-problems at each level increases by a certain factor, the value of f(n) will become polynomially smaller than nlogb a. 
Thus, the time complexity is oppressed by the cost of the last level ie. nlogb a

2. If the cost of solving the sub-problem at each level is nearly equal, then the value of f(n) will be nlogb a. Thus, the time complexity will be f(n) times the 
total number of levels ie. nlogb a * log n.

3. If the cost of solving the subproblems at each level decreases by a certain factor, the value of f(n) will become polynomially larger than nlogb a. Thus, 
the time complexity is oppressed by the cost of f(n).




-> Solved Example of Master Theorem

T(n) = 3T(n/2) + n2
Here,
a = 3
n/b = n/2
f(n) = n2
logb a = log2 3 ≈ 1.58 < 2
ie. f(n) < nlogb
a+ϵ , where, ϵ is a constant.
Case 3 implies here.
Thus, T(n) = f(n) = Θ(n2) 
Master Theorem Limitations




-> The master theorem cannot be used if:

   • T(n) is not monotone. eg. T(n) = sin n
   • f(n) is not a polynomial. eg. f(n) = 2n
   • a is not a constant. eg. a = 2n
   • a < 1




********** Divide and Conquer Algorithm **********

-> A divide and conquer algorithm is a strategy of solving a large problem by

   1. breaking the problem into smaller sub-problems
   2. solving the sub-problems, and
   3. combining them to get the desired output.

-> To use the divide and conquer algorithm, recursion is used.




********** How Divide and Conquer Algorithms Work? **********

-> Here are the steps involved:
1. Divide: Divide the given problem into sub-problems using recursion.
2. Conquer: Solve the smaller sub-problems recursively. If the subproblem is small enough, then solve it directly.
3. Combine: Combine the solutions of the sub-problems that are part of the recursive process to solve the actual problem.


********** Divide and Conquer Vs Dynamic approach ***********

-> The divide and conquer approach divides a problem into smaller subproblems; these subproblems are further solved recursively. The result of each subproblem 
   is not stored for future reference, whereas, in a dynamic approach, the result of each subproblem is stored for future reference.
   
-> Use the divide and conquer approach when the same subproblem is not solved multiple times. 
-> Use the dynamic approach when the result of a subproblem is to be used multiple times in the future.






********** Advantages of Divide and Conquer Algorithm **********

   • The complexity for the multiplication of two matrices using the naive method is O(n^3), whereas using the divide and conquer approach (i.e. 
      Strassen's matrix multiplication) is O(n^2.8074). This approach also simplifies other problems, such as the Tower of Hanoi.
   • This approach is suitable for multiprocessing systems.
   • It makes efficient use of memory caches.


*********** Divide and Conquer Applications ***********

   • Binary Search
   • Merge Sort
   • Quick Sort
   • Strassen's Matrix multiplication
   • Karatsuba Algorithm




*********** Stack Data Structure ************

-> A stack is a useful data structure in programming. A stack is an object (an abstract data type).
-> It is just like a pile of plates kept on top of each other.
-> Stack representation similar to a pile of plate.


-> Think about the things you can do with such a pile of plates
• Put a new plate on top
• Remove the top plate


-> If you want the plate at the bottom, you must first remove all the plates on top. 
-> Such an arrangement is called Last In First Out - the last item that is the first item to go out.




************ LIFO Principle of Stack **********

-> In programming terms, putting an item on top of the stack is called push and removing an item is called pop.




*********** Basic Operations of Stack ***********

-> A stack is an object (an abstract data type - ADT) that allows the following operations:

   • Push: Add an element to the top of a stack
   • Pop: Remove an element from the top of a stack
   • IsEmpty: Check if the stack is empty
   • IsFull: Check if the stack is full
   • Peek: Get the value of the top element without removing it




********** Stack Time Complexity ***********

-> For the array-based implementation of a stack, the push and pop operations take constant time, i.e. O(1)




********** Applications of Stack Data Structure **********

-> Although stack is a simple data structure to implement, it is very powerful. 

-> The most common uses of a stack are:

   • To reverse a word - Put all the letters in a stack and pop them out. Because of the LIFO order of stack, you will get the letters in reverse order.
   • In compilers - Compilers use the stack to calculate the value of expressions like 2 + 4 / 5 * (7 - 9) by converting the expression to prefix or postfix form.
   • In browsers - The back button in a browser saves all the URLs you have visited previously in a stack. Each time you visit a new page, it is added on 
      top of the stack. When you press the back button, the current URL is removed from the stack, and the previous URL is accessed.




*********** Queue Data Structure **********

-> A queue is a useful data structure in programming. A queue is an object (an abstract data type - ADT).

-> It is similar to the ticket queue outside a cinema hall, where the first person entering the queue is the first person who gets the ticket.


-> Queue follows the First In First Out (FIFO) rule - the item that goes in first is the item that comes out first.




********** FIFO Principle of Queue ***********

-> In programming terms, putting items in the queue is called enqueue, and removing items from the queue is called dequeue.




********** Basic Operations of Queue **********

-> A queue is an object (an abstract data structure - ADT) that allows the following operations:

   • Enqueue: Add an element to the end of the queue
   • Dequeue: Remove an element from the front of the queue
   • IsEmpty: Check if the queue is empty
   • IsFull: Check if the queue is full
   • Peek: Get the value of the front of the queue without removing it




*********** Complexity Analysis of Queue Operations ***********

-> The complexity of enqueue and dequeue operations in a queue using an array is O(1).




*********** Applications of Queue ************

   • CPU scheduling, Disk Scheduling
   • When data is transferred asynchronously between two processes. The queue is used for synchronization. For example: IO Buffers, pipes, file IO, etc.
   • Handling of interrupts in real-time systems.
   • Call Center phone systems use Queues to hold people calling them in order.




********** Types of Queues ************

There are four different types of queues:
• Simple Queue
• Circular Queue
• Priority Queue
• Double Ended Queue




*********** Simple Queue ***********

-> In a simple queue, insertion takes place at the rear and removal occurs at the front. 
-> It strictly follows the FIFO (First in First out) rule.




************ Circular Queue ***********

-> In a circular queue, the last element points to the first element making a circular link.




************ Simple Queue Vs Circular Queue ***********

-> The main advantage of a circular queue over a simple queue is better memory utilization. 
-> If the last position is full and the first position is empty, we can insert an element in the first position. 
-> This action is not possible in a simple queue.




*********** Priority Queue ************

-> A priority queue is a special type of queue in which each element is associated with a priority and is served according to its priority. 
-> If elements with the same priority occur, they are served according to their order in the queue.
-> Insertion occurs based on the arrival of the values and removal occurs based on priority.




************ Deque (Double Ended Queue) ************

-> In a double ended queue, insertion and removal of elements can be performed from either from the front or rear. 
-> Thus, it does not follow the FIFO (First In First Out) rule.




************ Circular Queue Data Structure ************

-> Circular queue avoids the wastage of space in a regular queue implementation using arrays.




************ How Circular Queue Works ************

-> Circular Queue works by the process of circular increment i.e. when we try to increment the pointer and we reach the end of the queue, we start from the 
   beginning of the queue.

-> Here, the circular increment is performed by modulo division with the queue size. 

-> That is,
      if REAR + 1 == 5 (overflow!), REAR = (REAR + 1)%5 = 0 (start of queue).
      
      
      
      
************ Circular Queue Complexity Analysis ************

-> The complexity of the enqueue and dequeue operations of a circular queue is O(1) for (array implementations).




************* Applications of Circular Queue ************

   • CPU scheduling
   • Memory management
   • Traffic Management


************ Priority Queue ***********

-> A priority queue is a special type of queue in which each element is associated with a priority and is served according to its priority. 
-> If elements with the same priority occur, they are served according to their order in the queue.

-> Generally, the value of the element itself is considered for assigning the priority.
-> For example, The element with the highest value is considered as the highest 
   priority element. 




************ Difference between Priority Queue and Normal Queue ***********

-> In a queue, the first-in-first-out rule is implemented whereas, in a priority queue, the values are removed on the basis of priority. 
-> The element with the highest priority is removed first.




*********** Implementation of Priority Queue ***********

-> Priority queue can be implemented using an array, a linked list, a heap data structure, or a binary search tree. 
-> Among these data structures, heap data structure provides an efficient implementation of priority queues.

-> A comparative analysis of different implementations of priority queue is given below.

   Operations          peek  insert    delete
   Linked List         O(1)  O(n)      O(1)
   Binary Heap         O(1)  O(log n)  O(log n)
   Binary Search Tree  O(1)  O(log n)  O(log n)




************ Priority Queue Operations ***********

-> Basic operations of a priority queue are inserting, removing, and peeking elements


1. Inserting an Element into the Priority Queue

Inserting an element into a priority queue (max-heap) is done by the following steps.
   
   • Insert the new element at the end of the tree.  
   • Insert an element at the end of the queue 
   • Heapify the tree. 
   • Heapify after insertion




2. Deleting an Element from the Priority Queue

Deleting an element from a priority queue (max-heap) is done as follows:

   • Select the element to be deleted. 
   • Swap it with the last element. 
   • Swap with the last leaf node element 
   • Remove the last element. 
   • Remove the last element leaf 
   • Heapify the tree. 
   • Heapify the priority queue 




3. Peeking from the Priority Queue (Find max/min)

Peek operation returns the maximum element from Max Heap or minimum element from Min Heap without deleting the node.




4. Extract-Max/Min from the Priority Queue

Extract-Max returns the node with maximum value after removing it from a Max Heap whereas Extract-Min returns the node with minimum value after removing it 
from Min Heap.




*********** Priority Queue Applications ************

Some of the applications of a priority queue are:
   • Dijkstra's algorithm
   • for implementing stack
   • for load balancing and interrupt handling in an operating system
   • for data compression in Huffman code




*********** Deque Data Structure ***********

-> Deque or Double Ended Queue is a type of queue in which insertion and removal of elements can be performed from either from the front or rear. 
-> Thus, it does not follow FIFO rule (First In First Out).




*********** Types of Deque ***********

   • Input Restricted Deque
   In this deque, input is restricted at a single end but allows deletion at both the ends.
   • Output Restricted Deque
   In this deque, output is restricted at a single end but allows insertion at both the ends.




*********** Operations on a Deque ************

-> Below is the circular array implementation of deque. In a circular array, if the array is full, we start from the beginning.
-> But in a linear array implementation, if the array is full, no more elements can be inserted. 
-> In each of the operations below, if the array is full, "overflow message" is thrown.




*********** Time Complexity ************

-> The time complexity of all the above operations is constant i.e. O(1).




*********** Applications of Deque Data Structure ************

1. In undo operations on software.
2. To store history in browsers.
3. For implementing both stacks and queues




********** Linked list Data Structure **********

-> A linked list data structure includes a series of connected nodes. 
-> Here, each node store the data and the address of the next node.


-> You have to start somewhere, so we give the address of the first node a special name called HEAD.
-> Also, the last node in the linked list can be identified because its next portion points to NULL.


-> You might have played the game Treasure Hunt, where each clue includes the information about the next clue. That is how the linked list operates.


********** Representation of Linked List **********

Each node consists:
• A data item
• An address of another node.




-> The power of a linked list comes from the ability to break the chain and rejoin it. 

E.g. if you wanted to put an element 4 between 1 and 2, the steps would be:
• Create a new struct node and allocate memory to it.
• Add its data value as 4
• Point its next pointer to the struct node containing 2 as the data value
• Change the next pointer of "1" to the node we just created.




*********** Linked List Complexity ***********

Time Complexity

Operations  Worst case  Average Case
Search      O(n)        O(n)
Insert      O(1)        O(1)
Deletion    O(1)        O(1)


Space Complexity: O(n)




********** Linked List Applications **********

• Dynamic memory allocation
• Implemented in stack and queue
• In undo functionality of softwares
• Hash tables, Graphs




*********** Linked List Operations: Traverse, Insert and Delete **********

Two important points to remember:
• head points to the first node of the linked list
• next pointer of the last node is NULL, so if the next current node is NULL, we have reached the end of the linked list.




********** Traverse a Linked List **********

-> Displaying the contents of a linked list is very simple.
-> We keep moving the temp node to the next one and display its contents.
-> When temp is NULL, we know that we have reached the end of the linked list so we get out of the while loop.




********** Insert Elements to a Linked List **********

-> You can add elements to either the beginning, middle or end of the linked list.


1. Insert at the beginning
• Allocate memory for new node
• Store data
• Change next of new node to point to head
• Change head to point to recently created node


2. Insert at the End
• Allocate memory for new node
• Store data
• Traverse to last node
• Change next of last node to recently created node


3. Insert at the Middle
• Allocate memory and store data for new node
• Traverse to node just before the required position of new node
• Change next pointers to include new node in between




********** Delete from a Linked List **********

-> You can delete either from the beginning, end or from a particular position.


1. Delete from beginning
• Point head to the second node


2. Delete from end
• Traverse to second last element
• Change its next pointer to null


3. Delete from middle
• Traverse to element before the element to be deleted
• Change next pointers to exclude the node from the chain




********** Types of Linked List **********

There are three common types of Linked List.
• Singly Linked List
• Doubly Linked List
• Circular Linked List




********** Singly Linked List **********

-> It is the most common. Each node has data and a pointer to the next node.




********** Doubly Linked List **********

-> We add a pointer to the previous node in a doubly-linked list. Thus, we can go in either direction: forward or backward.




********** Circular Linked List **********

-> A circular linked list is a variation of a linked list in which the last element is linked to the first element. 
-> This forms a circular loop.


-> A circular linked list can be either singly linked or doubly linked.
• for singly linked list, next pointer of last item points to the first item.
• In the doubly linked list, prev pointer of the first item points to the last item as well.




************ Hash Table **********

-> The Hash table data structure stores elements in key-value pairs where
• Key- unique integer that is used for indexing the values
• Value - data that are associated with keys.




*********** Hashing **********

-> Hashing is a technique of mapping a large set of arbitrary data to tabular indexes using a hash function. 
-> It is a method for representing dictionaries for large datasets.
-> It allows lookups, updating and retrieval operation to occur in a constant time i.e. O(1).




*********** Why Hashing is Needed **********

-> After storing a large amount of data, we need to perform various operations on these data. 
-> Lookups are inevitable for the datasets. 
-> Linear search and binary search perform lookups/search with time complexity of O(n) and O(log n) respectively. 
-> As the size of the dataset increases, these complexities also become significantly high which is not acceptable.

-> We need a technique that does not depend on the size of data. 
-> Hashing allows lookups to occur in constant time i.e. O(1)




*********** Hash Function **********

-> A hash function is used for mapping each element of a dataset to indexes in the table.

-> In a hash table, a new index is processed using the keys. 
-> And, the element corresponding to that key is stored in the index. This process is called hashing.

-> Let k be a key and h(x) be a hash function.
-> Here, h(k) will give us a new index to store the element linked with k.




*********** Hash Collision ***********

-> When the hash function generates the same index for multiple keys, there will be a conflict (what value to be stored in that index). 
-> This is called a hash collision.


-> We can resolve the hash collision using one of the following techniques.
• Collision resolution by chaining
• Open Addressing: Linear/Quadratic Probing and Double Hashing




1. Collision resolution by chaining
-> In chaining, if a hash function produces the same index for multiple elements, these elements are stored in the same index by using a doubly-linked list.
-> If j is the slot for multiple elements, it contains a pointer to the head of the list of elements. If no element is present, j contains NIL.

2. Open Addressing
-> Unlike chaining, open addressing doesn't store multiple elements into the same slot. 
-> Here, each slot is either filled with a single key or left NIL.


Different techniques used in open addressing are:

i. Linear Probing
-> In linear probing, collision is resolved by checking the next slot.
   
   h(k, i) = (h′(k) + i) mod m
   where,
   • i = {0, 1, ….}
   • h'(k) is a new hash function

-> If a collision occurs at h(k, 0), then h(k, 1) is checked. 
-> In this way, the value of i is incremented linearly.


-> The problem with linear probing is that a cluster of adjacent slots is filled. 
-> When inserting a new element, the entire cluster must be traversed. 
-> This adds to the time required to perform operations on the hash table.




ii. Quadratic Probing
-> It works similar to linear probing but the spacing between the slots is increased (greater than one) by using the following relation.

   h(k, i) = (h′(k) + c1i + c2i^2) mod m
   where,
   • c1 and c2 are positive auxiliary constants,
   • i = {0, 1, ….}




iii. Double hashing
-> If a collision occurs after applying a hash function h(k), then another hash function is calculated for finding the next slot.

   h(k, i) = (h1(k) + ih2(k)) mod m




*********** Good Hash Functions **********

-> A good hash function may not prevent the collisions completely however it can reduce the number of collisions.



-> Here, we will look into different methods to find a good hash function

1. Division Method
-> If k is a key and m is the size of the hash table, the hash function h() is calculated as:

   h(k) = k mod m

-> For example, If the size of a hash table is 10 and k = 112 then h(k) = 112 mod 10 = 2. 
-> The value of m must not be the powers of 2. This is because the powers of 2 in binary format are 10, 100, 1000, …. 
-> When we find k mod m, we will always get the lower order p-bits.
   if m = 22, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 01
   if m = 23, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 001
   if m = 24, k = 17, then h(k) = 17 mod 22 = 10001 mod 100 = 0001
   if m = 2p, then h(k) = p lower bits of m




2. Multiplication Method

   h(k) = ⌊m(kA mod 1)⌋
   where,
   • kA mod 1 gives the fractional part kA,
   • ⌊ ⌋ gives the floor value
   • A is any constant. The value of A lies between 0 and 1. But, an optimal choice will be ≈ (√5-1)/2 suggested by Knuth.




3. Universal Hashing

-> In Universal hashing, the hash function is chosen at random independent of keys




********** Applications of Hash Table **********

-> Hash tables are implemented where
• constant time lookup and insertion is required
• cryptographic applications
• indexing data is required




********** Heap Data Structure **********

-> Heap data structure is a complete binary tree that satisfies the heap property. It is also called as a binary heap.

-> A complete binary tree is a special binary tree in which
• every level, except possibly the last, is filled
• all the nodes are as far left as possible




*********** Heap Property **********

-> Heap Property is the property of a node in which:

• (for max heap) key of each node is always greater than its child node/s and the key of the root node is the largest among all other nodes;

• (for min heap) key of each node is always smaller than the child node/s and the key of the root node is the smallest among all other nodes.




********** Heap Operations **********

-> Some of the important operations performed on a heap are described below along with their algorithms: Heapify




********** Heapify **********

->Heapify is the process of creating a heap data structure from a binary tree. It is used to create a Min-Heap or a Max-Heap.

   1. Let the input array.
   2. Create a complete binary tree from the array
   3. Start from the first index of non-leaf node whose index is given by n/2 - 1.
   4. Set current element i as largest.
   5. The index of left child is given by 2i + 1 and the right child is given by 2i + 2.
      If leftChild is greater than currentElement (i.e. element at ith index), set leftChildIndex as largest.
      If rightChild is greater than element in largest, set rightChildIndex as largest.
   6. Swap largest with currentElement
   7. Repeat steps 3-7 until the subtrees are also heapified.





*********** Insert Element into Max Heap **********

1. Insert the new element at the end of the tree.
2. Heapify the tree.

-> For Min Heap, the above algorithm is modified so that parentNode is always smaller than newNode.


********** Delete Element from Max Heap **********

1. Select the element to be deleted.
2. Swap it with the last element.
3. Remove the last element.
4. Heapify the tree.

-> For Min Heap, above algorithm is modified so that both childNodes are greater smaller than currentNode.




*********** Peek (Find max/min) **********

-> Peek operation returns the maximum element from Max Heap or minimum element from Min Heap without deleting the node.

-> For both Max heap and Min Heap

   return rootNode




********** Extract-Max/Min **********

-> Extract-Max returns the node with maximum value after removing it from a Max Heap.
-> whereas Extract-Min returns the node with minimum after removing it from Min Heap.




*********** Heap Data Structure Applications **********

• Heap is used while implementing a priority queue.
• Dijkstra’s Algorithm
• Heap Sort




********** Tree Data Structure **********

A tree is a nonlinear hierarchical data structure that consists of nodes connected by edges.




********** Linear Vs Non-Linear Data Structure ***********

-> In linear data structure, all data elements are present at a single level. 
-> Linear data structures are easier to implement.

-> In non-linear data structure, data elements are hierarchically connected and are present at various levels. 
-> In non-linear data structure, data elements are present at multiple levels.




********** Why Tree Data Structure? **********

-> Other data structures such as arrays, linked list, stack, and queue are linear data structures that store data sequentially. 
-> In order to perform any operation in a linear data structure, the time complexity increases with the increase in the data size. 
-> But, it is not acceptable in today's computational world.

-> Different tree data structures allow quicker and easier access to the data as it is a non-linear data structure.




********** Tree Terminologies **********

Node:

-> A node is an entity that contains a key or value and pointers to its child nodes.
-> The last nodes of each path are called leaf nodes or external nodes that do not contain a link/pointer to child nodes.
-> The node having at least a child node is called an internal node.



Edge:

-> It is the link between any two nodes.



Root:

-> It is the topmost node of a tree.


Height of a Node:

-> The height of a node is the number of edges from the node to the deepest leaf (ie. the longest path from the node to a leaf node).


Depth of a Node:

-> The depth of a node is the number of edges from the root to the node


Height of a Tree:

-> The height of a Tree is the height of the root node or the depth of the deepest node.


Degree of a Node:

-> The degree of a node is the total number of branches of that node.


Forest:

-> A collection of disjoint trees is called a forest.


Creating forest from a tree:

-> You can create a forest by cutting the root of a tree




********** Types of Tree **********

There are mainly four types of Tree:
1. Binary Tree
2. Binary Search Tree
3. AVL Tree
4. B-Tree




********** Tree Applications **********

   • Binary Search Trees(BSTs) are used to quickly check whether an element is present in a set or not.
   • Heap is a kind of tree that is used for heap sort.
   • A modified version of a tree called Tries is used in modern routers to store routing information.
   • Most popular databases use B-Trees and T-Trees, which are variants of the tree structure we learned above to store their data
   • Compilers use a syntax tree to validate the syntax of every program you write.




********** Tree Traversal - inorder, preorder and postorder **********

-> Traversing a tree means visiting every node in the tree. 
-> You might, for instance, want to add all the values in the tree or find the largest one. For all these operations, you will need to visit each node of the tree.


-> Linear data structures like arrays, stacks, queues, and linked list have only one way to read the data. 
-> But a hierarchical data structure like a tree can be traversed in different ways.


-> According to this structure, every tree is a combination of
• A node carrying data
• Two subtrees

-> Remember that our goal is to visit each node, so we need to visit all the nodes in the subtree, 
-> visit the root node and visit all the nodes in the right subtree as well.


-> Depending on the order in which we do this, there can be three types of traversal.


Inorder traversal:

1. First, visit all the nodes in the left subtree
2. Then the root node
3. Visit all the nodes in the right subtree


Preorder traversal:

1. Visit root node
2. Visit all the nodes in the left subtree
3. Visit all the nodes in the right subtree


Postorder traversal:

1. Visit all the nodes in the left subtree
2. Visit all the nodes in the right subtree
3. Visit the root node




********** Binary Tree **********

-> A binary tree is a tree data structure in which each parent node can have at most two children.




********** Types of Binary Tree ***********

Full Binary Tree:

-> A full Binary tree is a special type of binary tree in which every parent node/internal node has either two or no children.


Perfect Binary Tree:

-> A perfect binary tree is a type of binary tree in which every internal node has exactly two child nodes and all the leaf nodes are at the same level.



Complete Binary Tree:

-> A complete binary tree is just like a full binary tree, but with two major differences

   1. Every level must be completely filled
   2. All the leaf elements must lean towards the left.
   3. The last leaf element might not have a right sibling i.e. a complete binary tree doesn't have to be a full binary tree.



Degenerate or Pathological Tree:

-> A degenerate or pathological tree is the tree having a single child either left or right.


Skewed Binary Tree:

-> A skewed binary tree is a pathological/degenerate tree in which the tree is either dominated by the left nodes or the right nodes. 


Thus, there are two types of skewed binary tree: 
1.left-skewed binary tree.
2.right-skewed binary tree.



Balanced Binary Tree:

-> It is a type of binary tree in which the difference between the height of the left and the right subtree for each node is either 0 or 1.


********** Binary Tree Applications ***********

   • For easy and quick access to data
   • In router algorithms
   • To implement heap data structure
   • Syntax tree














